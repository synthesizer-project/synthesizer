{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Survey Pipeline\n",
    "\n",
    "If you have a galaxy catalog (either of `Parametric` origin or from a simulation), an [`EmissionModel`](../emission_models/emission_models.rst), and a set of [instruments](../instrumentation/instrument_example.ipynb) you want observables for, you can easily write a pipeline to generate the observations you want using the Synthesizer UI. However, lets say you have a new catalog you want to run the same analysis on, or a whole different set of instruments you want to use. You could modify your old pipeline or write a whole new pipeline, but thats a lot of work and boilerplate. \n",
    "\n",
    "This is where the `Survey` shines. Instead, of having to write a pipeline, the `Survey` class is a high-level interface that allows you to easily generate observations for a given catalog, emission model, and set of instruments. All you need to do is define a galaxy loader, setup the ``Survey`` object, and run the observable methods you want to include. Possible observables include:\n",
    "\n",
    "- Spectra.\n",
    "- Emission Lines.\n",
    "- Photometry.\n",
    "- Images (with or without PSF convolution/noise).\n",
    "- Spectral data cubes (IFUs) [WIP].\n",
    "- Instrument specific spectroscopy [WIP].\n",
    "\n",
    "The ``Survey`` will generate all the requested observations for all (compatible) instruments and galaxies, before writing them out to a standardised HDF5 format.\n",
    "\n",
    "As a bonus, the abstraction into the `Survey` class allows for easy parallelization of the analysis, not only over local threads but optionally over MPI. \n",
    "\n",
    "In the following sections we will show how to instantiate and use a ``Survey`` object to generate observations for a given catalog, emission model, and set of instruments.\n",
    "\n",
    "## Setting up a ``Survey`` object\n",
    "\n",
    "Before we instatiate a survey we need to define its \"dependencies\". These are a method to load a galaxy catalog, an emission model, and a set of instruments. \n",
    "\n",
    "### Defining a galaxy loader\n",
    "\n",
    "The galaxy loader function can be distributed across a number of threads (also MPI ranks but we'll cover this in more detail below). To ensure the galaxy loader works and is parallelisable it must adhere to a set of rules:\n",
    "\n",
    "- It must return a single ``Galaxy`` object or ``None``. The latter of these is to handle any galaxies which failed to be loaded. These will be sanitised out of the catalog before any analysis is run.\n",
    "- It's first argument must be the galaxy's \"index\" in the catalog. This argument must be called \"gal_index\" since this is how we check the function is compatible under the hood. For instance, if you have a HDF5 file from which you are loading a ``Galaxy`` this index should be the index into the file for the galaxy you want to load. \n",
    "- It can take any number of additional arguments and keyword arguments.\n",
    "\n",
    "Below we define a fake galaxy loader for illustrative purposes. This function generates a particle based galaxy from a parametric star formation and metallicity history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from unyt import Msun, Mpc, Myr\n",
    "\n",
    "from synthesizer.particle.stars import sample_sfhz\n",
    "from synthesizer.parametric.stars import Stars as ParametricStars\n",
    "from synthesizer.parametric import SFH, ZDist\n",
    "from synthesizer import Galaxy\n",
    "\n",
    "def galaxy_loader(gal_index, grid):\n",
    "    \"\"\"\n",
    "    Load a fake particle Galaxy.\n",
    "    \n",
    "    Args:\n",
    "        gal_index (int): \n",
    "            The index of the galaxy to load. (Here, this is unused \n",
    "            but must be included.)\n",
    "        grid (synthesizer.grid.Grid): \n",
    "            The grid object to use for defining the SFZH.\n",
    "    \"\"\"\n",
    "    # Initialise the parametric Stars object\n",
    "    param_stars = ParametricStars(\n",
    "        grid.log10age,\n",
    "        grid.metallicity,\n",
    "        sf_hist=SFH.Constant(max_age= 100 * Myr),\n",
    "        metal_dist=ZDist.DeltaConstant(metallicity=0.01),\n",
    "        initial_mass=10**10 *Msun,\n",
    "    )\n",
    "\n",
    "    # Define the number of stellar particles we want\n",
    "    n = int(100 * (np.random.rand() + 0.5))\n",
    "\n",
    "    # Sample the parametric SFZH, producing a particle Stars object\n",
    "    # we will also pass some keyword arguments for some example attributes\n",
    "    part_stars = sample_sfhz(\n",
    "        sfzh=param_stars.sfzh,\n",
    "        log10ages=param_stars.log10ages,\n",
    "        log10metallicities=param_stars.log10metallicities,\n",
    "        nstar=n,\n",
    "        current_masses=np.full(n, 10**9 / n) * Msun,\n",
    "        redshift=1,\n",
    "        coordinates=np.random.normal(0, 0.01, (n, 3)) * Mpc,\n",
    "        centre=np.zeros(3) * Mpc,\n",
    "        smoothing_lengths=np.ones(n) * 0.01 * np.random.rand(n) * Mpc,\n",
    "    )\n",
    "\n",
    "    # And create the galaxy\n",
    "    gal = Galaxy(\n",
    "        stars=part_stars,\n",
    "        redshift=1,\n",
    "    )\n",
    "\n",
    "    return gal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way of defining a loader leaves the definition of a ``Galaxy`` entirely in the users hands. You are free to add whatever attributes you see fit, and can load data from any source you desire. \n",
    "\n",
    "Notice here how we have 2 arguments. The required ``gal_index``, and then the ``grid`` which our loader needs to define the SFZH grid axes. We'll provide this argument later on when we want to run our survey. \n",
    "\n",
    "### Defining an emission model\n",
    "\n",
    "The ``EmissionModel`` defines the emissions we'll generate, including the origin and any reprocessing the emission undergoes. For more details see the ``EmissionModel`` [docs](../emission_models/emission_models.rst). \n",
    "\n",
    "For demonstration, we'll use a simple premade ``IntrinsicEmission`` model which defines the intrinsic stellar emission (i.e. stellar emission without any ISM dust reprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizer.emission_models import IntrinsicEmission\n",
    "from synthesizer.grid import Grid\n",
    "\n",
    "# Get the grid\n",
    "grid_dir = \"../../../tests/test_grid/\"\n",
    "grid_name = \"test_grid\"\n",
    "grid = Grid(grid_name, grid_dir=grid_dir)\n",
    "\n",
    "model = IntrinsicEmission(grid, fesc=0.1)\n",
    "model.set_per_particle(True)  # we want per particle emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the instruments\n",
    "\n",
    "We don't need any instruments if all we want is spectra at the resolution of the ``Grid`` or emission lines. However, to get anything more sophisticated we need ``Instruments`` that define the technical specifications of the observations we want to generate. For a full breakdown see the instrumentation [docs](../instrumentation/instrument_example.ipynb).\n",
    "\n",
    "Here we'll define a simple set of instruments including a subset of NIRCam filters (capable of imaging with a 0.1 kpc resolution) and a set of UVJ top hat filters (only capable of photometry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unyt import angstrom, kpc\n",
    "from synthesizer.instruments import FilterCollection, UVJ\n",
    "from synthesizer.instruments import Instrument\n",
    "\n",
    "\n",
    "# Get the filters\n",
    "lam = np.linspace(10**3, 10**5, 1000) * angstrom\n",
    "webb_filters = FilterCollection(\n",
    "    filter_codes=[\n",
    "    f\"JWST/NIRCam.{f}\"\n",
    "    for f in [\"F090W\", \"F150W\", \"F200W\", \"F277W\", \"F356W\", \"F444W\"]\n",
    "],\n",
    "new_lam=lam,\n",
    ")\n",
    "uvj_filters= UVJ(new_lam=lam)\n",
    "\n",
    "# Instatiate the instruments\n",
    "webb_inst = Instrument(\"JWST\", filters=webb_filters, resolution=0.1 * kpc)\n",
    "uvj_inst = Instrument(\"UVJ\", filters=uvj_filters)\n",
    "instruments = webb_inst + uvj_inst \n",
    "\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the ``Survey`` object\n",
    "\n",
    "Now we have all the ingredients we need to instantiate a ``Survey`` object. All we need to do now is pass them into the ``Survey`` object alongside the number of galaxies in the catalog in total and the number of threads we want to use during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthesizer.survey.survey import Survey\n",
    "\n",
    "survey = Survey(gal_loader_func=galaxy_loader,  emission_model=model, n_galaxies=10, instruments=instruments, nthreads=4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we got a log out of the ``Survey`` object detailing the basic setup. The ``Survey`` will automatically output logging information to the console but this can be supressed by passing ``verbose=0`` which limit the outputs to saying hello, goodbye, and any errors that occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = Survey(gal_loader_func=galaxy_loader,  emission_model=model, n_galaxies=10, instruments=instruments, nthreads=4, verbose=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from synthesizer.kernel_functions import Kernel\n",
    "\n",
    "from synthesizer.parametric.morphology import Sersic2D\n",
    "\n",
    "from unyt import kpc, angstrom, Msun, Myr, Mpc\n",
    "import numpy as np\n",
    "from astropy.cosmology import Planck18 as cosmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the SPH kernel\n",
    "sph_kernel = Kernel()\n",
    "kernel = sph_kernel.get_kernel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = Survey(galaxy_loader, model, 10, instruments, nthreads=8)\n",
    "survey.load_galaxies(grid=grid)\n",
    "survey.get_spectra(cosmo=cosmo)\n",
    "survey.get_lines(line_ids=grid.available_lines)\n",
    "survey.get_photometry_luminosities()\n",
    "survey.get_photometry_fluxes()\n",
    "survey.get_images_luminosity(fov=50 * kpc, kernel=kernel)\n",
    "survey.get_images_flux(fov=50* kpc, kernel=kernel)\n",
    "survey.write(\"output.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey.galaxies[0].stars.particle_photo_lnu"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
